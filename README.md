# K-Nearest-Neighbours-KNN-and-The-Naive-Bayes-Classifier-Models
K Nearest Neighbours (KNN) and The Naive Bayes Classifier Machine Learning models
## Titanic Disaster Prediction Model using KNN

Model that determines whether or not a passenger survived the titanic disaster based on features such as gender,class, age,family and siblings members present and the port of embarkation .
-- Project Status: [ Completed]

### Project Intro/Objective
Predict the chances of a passenger surving the titanic disaster based on parameters such as age, passenger class, port of embarkation
Model that predicts the chances of passenger surviving with an accuracy score of 75% and above
### Context
RMS Titanic sank in the early morning hours of 15 April 1912 in the North Atlantic Ocean, four days into her maiden voyage from Southampton to New York City. The largest ocean liner in service at the time, Titanic had an estimated 2,224 people on board when she struck an iceberg at around 23:40 (ship's time)[a] on Sunday, 14 April 1912. Her sinking two hours and forty minutes later at 02:20 (ship's time; 05:18 GMT) on Monday, 15 April, resulted in the deaths of more than 1,500 people, making it one of the deadliest peacetime maritime disasters in history.
## Methods Used
1. Data Preparation and Cleaning
2. Feature Engineering
3. Exploratory Data Analysis
4. Modelling
5. Improving Model Performance
6. Evaluation
## Technologies Used
1. Pandas,
2. jupyter
3. Machine Learning KNN model
### Needs of this project
1. Download the two datasets from the given links:
2. Dataset 1 Source: [Train Dataset Source: Link (Links to an external site.), Test Dataset Source: Link (Links to an external site.)]
3. Dataset 2 Source: [Link (Links to an external site.)]
4. Randomly partition each dataset into two parts i.e 80 - 20  sets.
. For dataset 1, because we don't have the label for the test set, we will use the train set to create train and test data (i.e. splitting further), then perform K-nearest neighbor classification.
. For dataset 2, perform classification of the testing set samples using the Naive Bayes Classifier.
. Compute the accuracy (percentage of correct classification).
. Report the confusion matrix of each classifier.
. Repeat step 2 to step 4 twice, each time splitting the datasets differently i.e. 70-30, 60-40, then note the outcomes of your modeling.
. Suggest and apply at least one of the optimization techniques that you learned earlier this week.
. Provide further recommendations to improve both classifiers.
. Create a notebook for each project.  
